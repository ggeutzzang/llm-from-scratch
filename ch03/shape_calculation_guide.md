# 🧮 텐서 Shape 계산 완벽 가이드

## 핵심 규칙: "가장 뒤의 두 차원만 보면 된다!"

### 📌 기본 규칙

```
A @ B 계산 시:
  A shape: (..., n, m)
  B shape: (..., m, k)
  결과:    (..., n, k)

  👉 "가장 마지막 두 차원"만 행렬 곱셈처럼 생각!
  👉 앞의 차원들(...)은 그냥 "배치" - 보존됨
```

---

## 🔍 예제로 이해하기

### 예제 1: (1, 3, 2) @ (2, 2) = ?

```
(1, 3, 2) @ (2, 2)
 │  │  └─ m = 2
 │  └───── n = 3
 └──────── 배치 = 1

(2, 2)
 │  └─ k = 2
 └───── m = 2 (A의 마지막과 일치 ✓)

규칙 적용:
  A shape: (1, 3, 2)     → (..., n, m) = (..., 3, 2)
  B shape:    (2, 2)     → (m, k) = (2, 2)
  결과:    (1, 3, 2)     → (..., n, k) = (..., 3, 2)

✅ 답: (1, 3, 2)
```

**이해하기:**
- 배치 크기 1은 **보존**됨
- 3행 × 2열 행렬과 2행 × 2열 행렬 곱셈 → 3행 × 2열 결과
- 따라서 (1, 3, 2)

---

### 예제 2: (2, 4, 3) @ (3, 5) = ?

```
(2, 4, 3) @ (3, 5)
 │  │  └─ m = 3
 │  └───── n = 4
 └──────── 배치 = 2

(3, 5)
 │  └─ k = 5
 └───── m = 3 (일치 ✓)

규칙 적용:
  배치: 2 (보존)
  n: 4
  k: 5

✅ 답: (2, 4, 5)
```

---

### 예제 3: (2, 3, 4, 5) @ (5, 6) = ?

```
(2, 3, 4, 5) @ (5, 6)
 └────┬────┘ │  └─ m = 5
      │      └───── k = 6
   배치들

이전 배치: (2, 3) - 모두 보존!
마지막 두 차원: (4, 5) @ (5, 6) = (4, 6)

✅ 답: (2, 3, 4, 6)
```

**패턴:**
- 앞에 몇 개 차원이 있든 → 모두 보존
- 마지막 두 차원만 행렬 곱셈 규칙 적용

---

## 💡 어디까지가 "배치"인가?

```
A의 shape에서:
  가장 마지막 2개 차원 = 행렬 연산 대상
  나머지 모두 = 배치 (보존됨)

(1, 3, 2)
 └─ 보존
    └──────────── 행렬 곱셈 (3, 2)

(2, 4, 3, 5)
 └─────┬─────────── 배치 보존 (2, 4)
       └───────────── 행렬 곱셈 (3, 5)

(5, 2, 3, 4, 6)
 └────────┬────────── 배치 보존 (5, 2, 3)
          └────────── 행렬 곱셈 (4, 6)
```

---

## 🎯 빠르게 계산하는 체크리스트

### Step 1: 마지막 두 차원 확인
```
A @ B에서:
- A의 마지막 차원 = B의 첫 번째 차원? (같아야 함!)

(2, 3, 4, 5) @ (5, 6)
           └──┬─┘
             같음 ✓
```

### Step 2: 배치 차원 보존
```
A의 배치 (모든 것 except 마지막 2개): (2, 3)
결과에 그대로 붙임
```

### Step 3: 연산 결과 차원 계산
```
A의 마지막 2번째 차원 (행): 4
B의 마지막 차원 (열): 6
결과: (4, 6)
```

### Step 4: 조합
```
배치 + 연산 결과 = (2, 3) + (4, 6) = (2, 3, 4, 6)
```

---

## 🔗 멀티헤드 어텐션에서의 실제 예

### 예제: Q @ K^T

```
Q shape: (2, 2, 4, 1)    # batch=2, heads=2, tokens=4, dim=1
K^T shape: (2, 2, 1, 4)  # batch=2, heads=2, dim=1, tokens=4

계산:
  마지막 두 차원만 보기:
    (4, 1) @ (1, 4) = (4, 4)

  배치: (2, 2) 보존

  결과: (2, 2, 4, 4) ✓
```

**의미:**
- 배치 2개 샘플
- 각각 2개 헤드
- 각 헤드마다 4×4 행렬 (토큰×토큰 유사도)

---

### 예제: Attention_Weights @ V

```
Weights shape: (2, 2, 4, 4)  # 어텐션 가중치
V shape: (2, 2, 4, 1)        # 값들

계산:
  마지막 두 차원만 보기:
    (4, 4) @ (4, 1) = (4, 1)

  배치: (2, 2) 보존

  결과: (2, 2, 4, 1) ✓
```

---

## 🚀 심화: Broadcasting 이해하기

때로는 B가 A보다 차원이 적을 수 있습니다:

```
(2, 3, 4, 5) @ (5, 6)

PyTorch는 자동으로 B를 다음처럼 해석:
(5, 6) → (1, 1, 5, 6)

그 후:
  마지막 두 차원: (4, 5) @ (5, 6) = (4, 6)
  배치: (2, 3) 보존

결과: (2, 3, 4, 6)
```

---

## ⚡ 빠른 참조표

| A Shape | B Shape | A @ B Shape | 설명 |
|---------|---------|-------------|------|
| (3, 2) | (2, 5) | (3, 5) | 기본 행렬 곱 |
| (2, 3, 2) | (2, 5) | (2, 3, 5) | 배치 1개 보존 |
| (2, 3, 4, 2) | (2, 5) | (2, 3, 4, 5) | 배치 2개 보존 |
| (4, 3, 2) | (2, 5) | (4, 3, 5) | 배치 2개 보존 |
| (2, 2, 4, 1) | (2, 2, 1, 4) | (2, 2, 4, 4) | 멀티헤드 어텐션 |

---

## 🧠 암기할 한 가지

```
결과 shape = 배치 부분 + 행렬 연산 결과

배치 부분 = A shape 에서 마지막 2개 제외한 모든 것
행렬 연산 결과 = (A의 -2번째 차원, B의 -1번째 차원)
```

---

## ✅ 검증하는 법

**항상 마지막 두 차원만 확인:**

```python
# Python에서 빠르게 확인
A = torch.randn(2, 3, 4, 5)
B = torch.randn(5, 6)

# 확인: A[-2:] = (4, 5), B[-1] = 6
# 따라서 결과 = (2, 3, 4, 6)

result = A @ B
print(result.shape)  # torch.Size([2, 3, 4, 6])
```

---

## 🎓 최종 정리

> **텐서 곱셈의 마법: "마지막 2개 차원만 생각하세요"**
>
> 나머지는 자동으로 처리됩니다!
> - 배치 보존
> - 일치하지 않는 차원은 자동 확대 (broadcasting)
