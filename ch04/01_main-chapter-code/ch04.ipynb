{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch04/01_main-chapter-code/ch04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8",
      "metadata": {
        "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 예제 코드입니다.<br>\n",
        "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9295b2-182b-490b-8325-83a67c4a001d",
      "metadata": {
        "id": "ce9295b2-182b-490b-8325-83a67c4a001d"
      },
      "source": [
        "# 4장: 밑바닥부터 GPT 모델 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
      "metadata": {
        "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
        "outputId": "14c5900b-bb3b-4c4b-e0cd-953b3224e359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "맷플롯립 버전: 3.10.0\n",
            "파이토치 버전: 2.6.0+cu124\n",
            "tiktoken 버전: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"맷플롯립 버전:\", version(\"matplotlib\"))\n",
        "print(\"파이토치 버전:\", version(\"torch\"))\n",
        "print(\"tiktoken 버전:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02",
      "metadata": {
        "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02"
      },
      "source": [
        "- 이 장에서 GPT와 유사한 LLM 구조를 구현합니다. 다음 장에서는 이 LLM 훈련하는데 초점을 맞추겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01",
      "metadata": {
        "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/01.webp\" width=\"650px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef",
      "metadata": {
        "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef"
      },
      "source": [
        "## 4.1 구조 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b",
      "metadata": {
        "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b"
      },
      "source": [
        "- 1장은 GPT와 Llama 같은 모델을 소개했습니다. 이런 모델은 원본 트랜스포머 구조의 디코더 부분을 기반으로 순차적으로 단어를 생성합니다.\n",
        "- 따라서 이런 LLM을 종종 디코더 기반 LLM이라 부릅니다.\n",
        "- 전통적인 딥러닝 모델과 비교하면 LLM은 규모가 큽니다. 이는 코드의 양이 아니라 방대한 파라미터 개수 때문입니다.\n",
        "- 앞으로 보겠지만 LLM 구조의 많은 구성 요소가 반복적입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251",
      "metadata": {
        "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/02.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99",
      "metadata": {
        "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99"
      },
      "source": [
        "- 이전 장에서 설명의 편의를 위해 토큰 입력과 출력의 임베딩 차원을 작게 했습니다.\n",
        "- 이 장에서는 작은 GPT-2 모델와 같은 임베딩 크기를 사용합니다.\n",
        "- 구체적으로 Radford et al.'s [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)에 나온 가장 작은 GPT-2 모델 구조(1억 2,400만 파라미터)를 구현하겠습니다(처음에는 1억 1,700만 파라미터라고 보고되었지만 나중에 모델 저장소에 수정된 값으로 공개되었습니다).\n",
        "- 여기서 구현한 모델은 3억 4,500만 파라미터, 7억 6,200만 파라미터, 15억 4,200만 파라미터를 가진 모델과 호환됩니다. 6장에서 이 구현에 사전 훈련된 가중치를 로드하는 방법을 알아 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21baa14d-24b8-4820-8191-a2808f7fbabc",
      "metadata": {
        "id": "21baa14d-24b8-4820-8191-a2808f7fbabc"
      },
      "source": [
        "- 1억 2,400만 파라미터 GPT-2 모델의 설정은 다음과 같습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5ed66875-1f24-445d-add6-006aae3c5707",
      "metadata": {
        "id": "5ed66875-1f24-445d-add6-006aae3c5707"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # 어휘사전 크기\n",
        "    \"context_length\": 1024, # 문맥 길이\n",
        "    \"emb_dim\": 768,         # 임베딩 차원\n",
        "    \"n_heads\": 12,          # 어텐션 헤드 개수\n",
        "    \"n_layers\": 12,         # 층 개수\n",
        "    \"drop_rate\": 0.1,       # 드롭아웃 비율\n",
        "    \"qkv_bias\": False       # 쿼리, 키, 값을 만들 때 편향 포함 여부\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4",
      "metadata": {
        "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4"
      },
      "source": [
        "- `\"vocab_size\"`는 BPE 토크나이저(2장 참조)에서 사용할 50,257 토큰으로 구성된 어휘 사전 크기를 나타냅니다.\n",
        "- `\"context_length\"`는 위치 임베딩(2장 참조)으로 모델이 다룰 수 있는 입력 토큰의 최대 개수입니다.\n",
        "- `\"emb_dim\"`은 임베딩 크기를 나타내며, 각 토큰을 768 차원의 벡터로 변환합니다.\n",
        "- `\"n_heads\"`는 멀티 헤드 어텐션 메커니즘(3장 참조)에 있는 어텐션 헤드의 개수입니다.\n",
        "- `\"n_layers\"`에는 모델에 있는 (이 장에서 소개할) 트랜스포머 블록의 개수를 지정합니다.\n",
        "- `\"drop_rate\"`는 과대적합을 막기 위한 드롭아웃 메커니즘(3장 참조)의 강도를 지정합니다(0.1은 은닉 유닛의 10%를 랜덤하게 제외한다는 의미입니다).\n",
        "- `\"qkv_bias\"`는 멀티 헤드 어텐션의 Linear 층에서 쿼리, 키, 값을 계산할 때 편향 유닛을 도입할지 여부를 결정합니다. 현대적인 LLM의 구성 방식을 따라서 처음에는 이 값을 비활성화하지만 오픈AI의 사전 훈련된 GPT-2 가중치를 모델로 로드할 때 이를 다시 살펴 보겠습니다(6장 참조)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4adce779-857b-4418-9501-12a7f3818d88",
      "metadata": {
        "id": "4adce779-857b-4418-9501-12a7f3818d88"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/03.webp\" width=\"650px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227",
      "metadata": {
        "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 더미 클래스\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 이 블록은 아무것도 하지 않고 입력을 그냥 반환합니다.\n",
        "        return x\n",
        "\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        # 층 정규화 인터페이스를 흉내내기 위한 매개변수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 이 블록은 아무것도 하지 않고 입력을 그냥 반환합니다.\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be",
      "metadata": {
        "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/04.webp?123\" width=\"650px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
      "metadata": {
        "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
        "outputId": "815d6ceb-ec07-43cc-88ac-28900a8b0267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "009238cd-0160-4834-979c-309710986bb0",
      "metadata": {
        "id": "009238cd-0160-4834-979c-309710986bb0",
        "outputId": "9d2f44b5-91c3-4a80-e454-1c8bb0dfed0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "출력 크기: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "logits = model(batch)\n",
        "print(\"출력 크기:\", logits.shape)\n",
        "print(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fad0fe-895d-4493-9e48-962e2d46c66f",
      "metadata": {
        "id": "f8fad0fe-895d-4493-9e48-962e2d46c66f"
      },
      "source": [
        "---\n",
        "\n",
        "**노트**\n",
        "\n",
        "- 이 코드를 윈도나 리눅스에서 실행하면 결괏값이 다음처럼 보일 수 있습니다:\n",
        "    \n",
        "```\n",
        "Output shape: torch.Size([2, 4, 50257])\n",
        "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
        "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
        "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
        "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
        "\n",
        "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
        "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
        "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
        "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
        "       grad_fn=<UnsafeViewBackward0>)\n",
        "```\n",
        "\n",
        "- 이는 난수 때문이며 문제가 되지 않으므로 이 장의 나머지 코드를 실행하는데 이슈가 없습니다.\n",
        "- 이런 차이가 생기는 한 가지 이유는 `nn.Dropout`이 파이토치가 컴파일된 운영체제에 따라 다르게 동작하기 때문입니다. 자세한 내용은 [파이토치 이슈 트래커](https://github.com/pytorch/pytorch/issues/121595)를 참고하세요.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8332a00-98da-4eb4-b882-922776a89917",
      "metadata": {
        "id": "f8332a00-98da-4eb4-b882-922776a89917"
      },
      "source": [
        "## 4.2 층 정규화로 활성화 정규화하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066cfb81-d59b-4d95-afe3-e43cf095f292",
      "metadata": {
        "id": "066cfb81-d59b-4d95-afe3-e43cf095f292"
      },
      "source": [
        "- LayerNorm([Ba et al. 2016](https://arxiv.org/abs/1607.06450))이라고도 불리는 층 정규화는 신경망 층의 활성화를 평균이 0이고 분산이 1이 되도록 조정합니다.\n",
        "- 이를 통해 훈련을 안정화하고 가중치 수렴 속도를 높일 수 있습니다.\n",
        "- 나중에 구현하겠지만 층 정규화는 트랜스포머 블록의 멀티 헤드 어텐션 모듈 전후에 적용됩니다. 또한 최종 출력 층 전에도 적용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314ac47a-69cc-4597-beeb-65bed3b5910f",
      "metadata": {
        "id": "314ac47a-69cc-4597-beeb-65bed3b5910f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/05.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab49940-6b35-4397-a80e-df8d092770a7",
      "metadata": {
        "id": "5ab49940-6b35-4397-a80e-df8d092770a7"
      },
      "source": [
        "- 작은 입력 샘플을 간단한 신경망 층에 통과시켜 층 정규화의 작동 방식을 알아 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
      "metadata": {
        "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
        "outputId": "8eb0e40f-b996-46df-b2a8-6a2f63ced8a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# 다섯 개의 차원(특성)을 가진 두 개의 훈련 샘플을 만듭니다.\n",
        "batch_example = torch.randn(2, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e",
      "metadata": {
        "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e"
      },
      "source": [
        "- 두 개의 입력에 대해 각각 평균과 분산을 계산해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
      "metadata": {
        "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
        "outputId": "8d2c4584-cf9f-4bba-8efc-d1c7558e835a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "분산:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "\n",
        "print(\"평균:\\n\", mean)\n",
        "print(\"분산:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "052eda3e-b395-48c4-acd4-eb8083bab958",
      "metadata": {
        "id": "052eda3e-b395-48c4-acd4-eb8083bab958"
      },
      "source": [
        "- 정규화는 두 입력(행)에 대해 독립적으로 적용됩니다. dim=-1을 사용하면 행 차원이 아니라 마지막 차원(이 경우 특성 차원)을 따라 계산이 수행됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570db83a-205c-4f6f-b219-1f6195dde1a7",
      "metadata": {
        "id": "570db83a-205c-4f6f-b219-1f6195dde1a7"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/06.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99",
      "metadata": {
        "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99"
      },
      "source": [
        "- 평균을 빼고, 분산의 제곱근(표준편차)으로 나누면 입력을 열(특성) 차원을 따라 평균이 0이고 분산이 1이 되도록 만듭니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
      "metadata": {
        "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
        "outputId": "9f894158-e094-4f96-df65-457405401066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정규화된 층 출력:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "평균:\n",
            " tensor([[9.9341e-09],\n",
            "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
            "분산:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "print(\"정규화된 층 출력:\\n\", out_norm)\n",
        "\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"평균:\\n\", mean)\n",
        "print(\"분산:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1",
      "metadata": {
        "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1"
      },
      "source": [
        "- 각 입력의 평균은 0이고 분산은 1입니다. 결과를 보기 쉽도록 파이토치의 과학적 표기법을 끌 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
      "metadata": {
        "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
        "outputId": "d8dc906d-8783-44ed-fa57-19f21d2a9c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "분산:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"평균:\\n\", mean)\n",
        "print(\"분산:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "944fb958-d4ed-43cc-858d-00052bb6b31a",
      "metadata": {
        "id": "944fb958-d4ed-43cc-858d-00052bb6b31a"
      },
      "source": [
        "- 위에서 각 입력의 특성을 정규화했습니다.\n",
        "- 이제 동일한 아이디어를 사용해 `LayerNorm` 클래스를 구현해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3333a305-aa3d-460a-bcce-b80662d464d9",
      "metadata": {
        "id": "3333a305-aa3d-460a-bcce-b80662d464d9"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72",
      "metadata": {
        "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72"
      },
      "source": [
        "**스케일 조정과 이동**\n",
        "\n",
        "- 평균을 빼고, 분산으로 나누어 정규화하는 것 이외에 두 개의 훈련 가능한 파라미터 `scale`과 `shift`를 추가했습니다.\n",
        "- 초기 `scale`(1)과 `shift`(0)은 아무런 영향을 미치지 못합니다. 하지만 `scale`과 `shift`가 훈련 가능한 파라미터이기 때문에 훈련 과정에서 두 파라미터를 조정하는 것이 훈련 작업에서 모델의 성능을 향상시킨다고 판단하는 경우 LLM이 자동으로 조정합니다.\n",
        "- 이를 통해 모델은 처리하는 데이터에 가잘 잘 맞는 스케일 조정과 이동을 학습할 수 있습니다.\n",
        "- 분산의 제곱근을 계산할 때 작은 값(`eps`)를 더합니다. 이는 분산이 0일 경우 0 나눗셈 오류를 방지하기 위해서입니다.\n",
        "\n",
        "**편향된 분산**\n",
        "- 위 분산 계산에서 `unbiased=False`는 $\\frac{\\sum_i (x_i - \\bar{x})^2}{n}$ 식으로 분산을 계산한다는 의미입니다. `n`은 샘플 크기입니다(여기서는 특성 또는 열 개수). 이 공식은 (분모가 `n-1`인) 베셀 보정(Bessel's correction)을 사용하지 않습니다. 따라서 편향된 분산을 추정합니다.\n",
        "- LLM에서 임베딩 차원 `n`은 매우 크므로 `n`과 `n-1`을 사용하는 차이는 무시할 수 있습니다.\n",
        "- 하지만 GPT-2가 정규화 층에 편향된 분산을 사용했으므로 나중에 사전 훈련된 가중치를 로드할 때 호환성을 위해 동일한 방식을 적용했습니다.\n",
        "- 이제 `LayerNorm`을 실제로 테스트해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "23b1000a-e613-4b43-bd90-e54deed8d292",
      "metadata": {
        "id": "23b1000a-e613-4b43-bd90-e54deed8d292"
      },
      "outputs": [],
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
      "metadata": {
        "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
        "outputId": "2d84e7c8-aabe-400d-d315-4f5b614d0cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "분산:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "\n",
        "print(\"평균:\\n\", mean)\n",
        "print(\"분산:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e136cfc4-7c89-492e-b120-758c272bca8c",
      "metadata": {
        "id": "e136cfc4-7c89-492e-b120-758c272bca8c"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/07.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11190e7d-8c29-4115-824a-e03702f9dd54",
      "metadata": {
        "id": "11190e7d-8c29-4115-824a-e03702f9dd54"
      },
      "source": [
        "## 4.3 GELU 활성화 함수를 사용하는 피드 포워드 네트워크 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169",
      "metadata": {
        "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169"
      },
      "source": [
        "- 이 절에서 LLM의 트랜스포머 블록에서 사용되는 작은 신경망 모듈을 구현합니다.\n",
        "- 딥러닝에서는 ReLU(Rectified Linear Unit) 활성화 함수가 간단하며 다양한 신경망 구조에서 효과적이기 때문에 널리 사용됩니다.\n",
        "- LLM에서는 전통적인 ReLU 외에도 다양한 종류의 활성화 함수가 사용됩니다. 대표적인 두 개의 함수는 GELU(Gaussian Error Linear Unit)와 SwiGLU(Swish-Gated Linear Unit)입니다.\n",
        "- GELU와 SwiGLU는 각각 가우스 오차 함수와 시그모이드 GLU(gated linear unit)을 사용한 더 복잡하고 부드러운 활성화 함수입니다. 간단한 ReLU와 달리 딥러닝 모델의 성능을 향상시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc",
      "metadata": {
        "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc"
      },
      "source": [
        "- GELU 활성화 함수([Hendrycks and Gimpel 2016](https://arxiv.org/abs/1606.08415))는 여러 방법으로 구현할 수 있습니다. 정확한 정의는 GELU(x) = x⋅𝛷(x)입니다. 여기서 𝛷(x)는 표준 가우스 누적 분포 함수(가우스 오차 함수)입니다.\n",
        "- 실제로는 계산하기 쉬운 근사식으로 구현합니다: $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
        "$ (원본 GPT-2 모델도 커브 피팅(curve fitting)으로 찾은 이 근사식을 사용했습니다)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f84694b7-95f3-4323-b6d6-0a73df278e82",
      "metadata": {
        "id": "f84694b7-95f3-4323-b6d6-0a73df278e82"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
      "metadata": {
        "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
        "outputId": "f4be4781-45ab-4e5b-b322-b640433418e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "# 샘플 데이터\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd01662-14cb-43fd-bffd-2d702813de2d",
      "metadata": {
        "id": "1cd01662-14cb-43fd-bffd-2d702813de2d"
      },
      "source": [
        "- 여기서 보듯이 ReLU는 양수는 그대로 출력하고 음수는 모두 0을 출력하는 구간별 선형 함수(piecewise linear function)입니다.\n",
        "- GELU는 부드러운 비선형 함수로, ReLU와 비슷하지만 모든 음수 값의 그레이디언트를 0으로 만들지 않습니다(대략 x = -0.75에서는 그레이디언트가 0이 됩니다).\n",
        "- 그다음 LLM의 트랜스포머 블록에 사용할 작은 신경망 모듈인 `FeedForward`를 구현해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9275c879-b148-4579-a107-86827ca14d4d",
      "metadata": {
        "id": "9275c879-b148-4579-a107-86827ca14d4d"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
      "metadata": {
        "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
        "outputId": "b8c2cf92-e456-4cbd-e188-e24119e446bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ],
      "source": [
        "print(GPT_CONFIG_124M[\"emb_dim\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a",
      "metadata": {
        "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/09.webp?12\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
      "metadata": {
        "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
        "outputId": "300e490d-05c1-4636-ba08-526d5148e903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ],
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "\n",
        "# 입력 크기: [batch_size, num_token, emb_size]\n",
        "x = torch.rand(2, 3, 768)\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f8756c5-6b04-443b-93d0-e555a316c377",
      "metadata": {
        "id": "8f8756c5-6b04-443b-93d0-e555a316c377"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/10.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5da2a50-04f4-4388-af23-ad32e405a972",
      "metadata": {
        "id": "e5da2a50-04f4-4388-af23-ad32e405a972"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/11.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89",
      "metadata": {
        "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89"
      },
      "source": [
        "## 4.4 숏컷 연결 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e",
      "metadata": {
        "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e"
      },
      "source": [
        "- 스킵 연결(skip connection)이나 잔차 연결(residual connection)이라고도 부르는 숏컷 연결(shortcut connection) 이면의 개념을 알아 보죠.\n",
        "- 원래 숏컷 연결은 컴퓨터 비전 분야의 심층 신경망(구체적으로 잔차 신경망(residual network))에서 그레이디언트 소실 문제를 완화하기 위해 제안되었습니다.\n",
        "- 숏컷 연결이 그레이디언트가 한 개 이상의 층을 건너 뛰어 네트워크에 흐를 수 있도록 짧은 다른 경로를 만든다는 것을 보여줍니다.\n",
        "- 이런 경로는 한 층의 출력을 이후 층의 출력에 더하여 만들어집니다.\n",
        "- 작은 샘플 네트워크로 이 아이디어를 설명해 보죠:\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/12.webp?123\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14cfd241-a32e-4601-8790-784b82f2f23e",
      "metadata": {
        "id": "14cfd241-a32e-4601-8790-784b82f2f23e"
      },
      "source": [
        "- 코드로 구현하면 다음과 같습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "05473938-799c-49fd-86d4-8ed65f94fee6",
      "metadata": {
        "id": "05473938-799c-49fd-86d4-8ed65f94fee6"
      },
      "outputs": [],
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            # 현재 층의 출력을 계산합니다.\n",
        "            layer_output = layer(x)\n",
        "            # 숏컷 연결을 적용할 수 있는지 확인합니다.\n",
        "            if self.use_shortcut and x.shape == layer_output.shape:\n",
        "                x = x + layer_output\n",
        "            else:\n",
        "                x = layer_output\n",
        "        return x\n",
        "\n",
        "\n",
        "def print_gradients(model, x):\n",
        "    # 정방향 계산\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # 타깃과 출력의 가까운 정도를 기반으로 손실을 계산합니다.\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # 그레이디언트를 계산하기 위한 역전파\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # 가중치의 그레이디언트의 평균 절댓값을 출력합니다.\n",
        "            print(f\"{name}의 평균 그레이디언트는 {param.grad.abs().mean().item()}입니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011",
      "metadata": {
        "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011"
      },
      "source": [
        "- 숏컷 연결이 **없을** 때 그레디언트 값을 출력해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c75f43cc-6923-4018-b980-26023086572c",
      "metadata": {
        "id": "c75f43cc-6923-4018-b980-26023086572c",
        "outputId": "6999c978-49d2-4dc4-dce2-2254823b3df6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight의 평균 그레이디언트는 0.00020173584925942123입니다.\n",
            "layers.1.0.weight의 평균 그레이디언트는 0.00012011159560643137입니다.\n",
            "layers.2.0.weight의 평균 그레이디언트는 0.0007152040489017963입니다.\n",
            "layers.3.0.weight의 평균 그레이디언트는 0.0013988736318424344입니다.\n",
            "layers.4.0.weight의 평균 그레이디언트는 0.005049645435065031입니다.\n"
          ]
        }
      ],
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=False\n",
        ")\n",
        "print_gradients(model_without_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837fd5d4-7345-4663-97f5-38f19dfde621",
      "metadata": {
        "id": "837fd5d4-7345-4663-97f5-38f19dfde621"
      },
      "source": [
        "- 그다음 숏컷 연결이 **있을** 때 그레이디언트 값을 출력합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
      "metadata": {
        "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
        "outputId": "60a09ef4-5248-4694-f010-42dd4b233c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight의 평균 그레이디언트는 0.22169791162014008입니다.\n",
            "layers.1.0.weight의 평균 그레이디언트는 0.20694105327129364입니다.\n",
            "layers.2.0.weight의 평균 그레이디언트는 0.32896995544433594입니다.\n",
            "layers.3.0.weight의 평균 그레이디언트는 0.2665732204914093입니다.\n",
            "layers.4.0.weight의 평균 그레이디언트는 1.3258540630340576입니다.\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=True\n",
        ")\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e",
      "metadata": {
        "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e"
      },
      "source": [
        "- 위 출력에서 볼 수 있듯이 숏컷 연결이 앞쪽 층(`layer.0` 층)의 그레이디언트 소실 문제를 막습습니다.\n",
        "- 숏컷 연결의 개념을 사용해 트랜스포머 블록을 구현하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae578ca-e564-42cf-8635-a2267047cdff",
      "metadata": {
        "id": "cae578ca-e564-42cf-8635-a2267047cdff"
      },
      "source": [
        "## 4.5 어텐션과 선형 층을 트랜스포머 블록에 연결하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3daac6f-6545-4258-8f2d-f45a7394f429",
      "metadata": {
        "id": "a3daac6f-6545-4258-8f2d-f45a7394f429"
      },
      "source": [
        "- 이 절에서 이전에 배운 개념을 소위 트랜스포머 블록에 결합합니다.\n",
        "- 트랜스포머 블록은 이전 층에서 다룬 코잘 멀티 헤드 어텐션 모듈과 앞서 다룬 피드 포워드 신경망을 결합합니다.\n",
        "- 또한 트랜스포머 블록은 드롭아웃과 숏컷 연결을 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 깃허브에서 previous_chapters.py 파일을 다운로드합니다.\n",
        "!wget https://bit.ly/43BW1j3 -O previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzy8BKIxFWEz",
        "outputId": "9f5b77d4-2732-4c0a-ec8e-f481f0d723a2"
      },
      "id": "zzy8BKIxFWEz",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-30 08:54:25--  https://bit.ly/43BW1j3\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch04/01_main-chapter-code/previous_chapters.py [following]\n",
            "--2025-05-30 08:54:25--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch04/01_main-chapter-code/previous_chapters.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4199 (4.1K) [text/plain]\n",
            "Saving to: ‘previous_chapters.py’\n",
            "\n",
            "previous_chapters.p 100%[===================>]   4.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-30 08:54:26 (66.1 MB/s) - ‘previous_chapters.py’ saved [4199/4199]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9",
      "metadata": {
        "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import MultiHeadAttention\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 어텐션 블록을 위한 숏컷 연결\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # 크기: [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # 원래 입력을 더합니다.\n",
        "\n",
        "        # 피드 포워드 블록을 위한 숏컷 연결\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # 원래 입력을 더합니다.\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b64d16-94a6-4d13-8c85-9494c50478a9",
      "metadata": {
        "id": "36b64d16-94a6-4d13-8c85-9494c50478a9"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/13.webp?1\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb",
      "metadata": {
        "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb"
      },
      "source": [
        "- 두 개의 입력 샘플이 있다고 가정해 보죠. 각 샘플은 여섯 개의 토큰으로 구성되고 각 토큰은 768차원의 임베딩 벡터입니다. 트랜스포머 블록이 셀프 어텐션과 피드 포워드 신경망을 적용하여 동일 크기의 출력을 반환합니다.\n",
        "- 이 출력을 이전 장에서 이야기한 문맥 벡터의 증강된 버전으로 생각할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
      "metadata": {
        "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
        "outputId": "8a99816d-d352-4150-ad1b-5d2374b89f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 크기: torch.Size([2, 4, 768])\n",
            "출력 크기: torch.Size([2, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "x = torch.rand(2, 4, 768)  # 크기: [batch_size, num_tokens, emb_dim]\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "\n",
        "print(\"입력 크기:\", x.shape)\n",
        "print(\"출력 크기:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13",
      "metadata": {
        "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/14.webp?1\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46618527-15ac-4c32-ad85-6cfea83e006e",
      "metadata": {
        "id": "46618527-15ac-4c32-ad85-6cfea83e006e"
      },
      "source": [
        "## 4.6 GPT 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457",
      "metadata": {
        "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457"
      },
      "source": [
        "- 트랜스포머 블록을 이 장의 서두에서 만들었던 GPT 구조에 연결해 보죠.\n",
        "- 트랜스포머 블록은 여러 번 반복됩니다. 1억 2,400만 파라미터의 GPT-2 모델의 경우 12번 반복합니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073",
      "metadata": {
        "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/15.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc",
      "metadata": {
        "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc"
      },
      "source": [
        "- 이를 코드로 구현하면 다음과 같습니다. 여기서 `cfg[\"n_layers\"] = 12`입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c61de39c-d03c-4a32-8b57-f49ac3834857",
      "metadata": {
        "id": "c61de39c-d03c-4a32-8b57-f49ac3834857"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # 크기 [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2750270f-c45d-4410-8767-a6adbd05d5c3",
      "metadata": {
        "id": "2750270f-c45d-4410-8767-a6adbd05d5c3"
      },
      "source": [
        "- 1억 2,400만 파라미터 모델의 설정을 사용해 랜덤한 초기 가중치로 GPT 모델을 만들었습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
      "metadata": {
        "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
        "outputId": "5a85b609-0e78-431d-bfd9-73fb26684d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 배치:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "출력 크기: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
            "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
            "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
            "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
            "\n",
            "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
            "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
            "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
            "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "out = model(batch)\n",
        "print(\"입력 배치:\\n\", batch)\n",
        "print(\"\\n출력 크기:\", out.shape)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e",
      "metadata": {
        "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e"
      },
      "source": [
        "- 이 모델을 다음 장에서 훈련해보겠습니다.\n",
        "- 크기를 간단히 계산해 보죠. 1억 2,400만 파라미터를 가지고 있는지 다음처럼 확인할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
      "metadata": {
        "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
        "outputId": "c6d9c75b-81f1-409f-89fd-d7aaed0ca12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 파라미터 개수: 163,009,536\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"총 파라미터 개수: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660",
      "metadata": {
        "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660"
      },
      "source": [
        "- 위에서 보듯이 이 모델의 파라미터 개수는 1억 2,400만개가 아니라 1억 6,300만개입니다. 왜일까요?\n",
        "- 원본 GPT-2 논문에서 연구자들은 가중치 묶기(weight tying)를 적용했습니다. 토큰 임베딩 층(`tok_emb`)의 가중치를 출력 층에 재사용한다는 의미이며, `self.out_head.weight = self.tok_emb.weight`처럼 설정합니다.\n",
        "- 토큰 임베딩 층은 50,257차원의 원-핫 인코딩된 입력 토큰을 768차원의 임베딩 표현에 투영합니다.\n",
        "- 출력 층은 768차원의 임베딩을 단어로 변환하기 위해 250,257차원의 표현으로 다시 투영합니다(다음 절에서 자세히 설명합니다).\n",
        "- 따라서 가중치 행렬의 크기를 보면 알 수 있듯이 임베딩 층과 출력 층의 파라미터 개수가 같습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
      "metadata": {
        "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
        "outputId": "90a42dd8-db39-4600-a922-bd58e772ac0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰 임베딩 층의 가중치 크기: torch.Size([50257, 768])\n",
            "출력 층의 가중치 크기: torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "print(\"토큰 임베딩 층의 가중치 크기:\", model.tok_emb.weight.shape)\n",
        "print(\"출력 층의 가중치 크기:\", model.out_head.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289",
      "metadata": {
        "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289"
      },
      "source": [
        "- 원본 GPT-2 논문에서 연구자들은 토큰 임베딩 행렬을 출력 행렬로 재사용했습니다.\n",
        "- 결과적으로 출력 층의 파라미터 개수를 빼면 1억 2,400만 파라미터의 모델이 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
      "metadata": {
        "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
        "outputId": "06f4ba3f-fa00-4114-b0a0-0291a937c751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 124,412,160\n"
          ]
        }
      ],
      "source": [
        "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"가중치 묶기를 고려한 훈련 가능한 파라미터 개수: {total_params_gpt2:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db",
      "metadata": {
        "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db"
      },
      "source": [
        "- 실제로는 가중치 묶기가 없는 모델이 훈련하기 쉽기 때문에 여기서는 구현하지 않습니다.\n",
        "- 하지만 5장에서 사준 훈련된 가중치를 로드할 때 가중치 묶기를 적용하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fea8be3-30a1-4623-a6d7-b095c6c1092e"
      },
      "source": [
        "### 연습문제 4.1: 피드 포워드 신경망과 어텐션 모듈에 있는 파라미터 수"
      ],
      "id": "5fea8be3-30a1-4623-a6d7-b095c6c1092e"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2751b0e5-ffd3-4be2-8db3-e20dd4d61d69",
        "outputId": "e1b2ef69-a78f-4ea1-f9c7-00845efb60df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerBlock(\n",
            "  (att): MultiHeadAttention(\n",
            "    (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ff): FeedForward(\n",
            "    (layers): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (1): GELU()\n",
            "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (norm1): LayerNorm()\n",
            "  (norm2): LayerNorm()\n",
            "  (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "print(block)"
      ],
      "id": "2751b0e5-ffd3-4be2-8db3-e20dd4d61d69"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1bcaffd1-0cf6-4f8f-bd53-ab88a37f443e",
        "outputId": "6c2a2d4f-d146-4caa-8016-96033653ea3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "피드 포워드 모듈에 있는 총 파라미터 수: 4,722,432\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in block.ff.parameters())\n",
        "print(f\"피드 포워드 모듈에 있는 총 파라미터 수: {total_params:,}\")"
      ],
      "id": "1bcaffd1-0cf6-4f8f-bd53-ab88a37f443e"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c1dd06c1-ab6c-4df7-ba73-f9cd54b31138",
        "outputId": "ccca7a2e-8f0c-4653-f13d-ff7abb40a267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어텐션 모듈에 있는 총 파라미터 수: 2,360,064\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in block.att.parameters())\n",
        "print(f\"어텐션 모듈에 있는 총 파라미터 수: {total_params:,}\")"
      ],
      "id": "c1dd06c1-ab6c-4df7-ba73-f9cd54b31138"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15463dec-520a-47b4-b3ad-e180394fd076"
      },
      "source": [
        "- 위는 하나의 트랜스포머 블록에 대한 결과입니다.\n",
        "- 1억 2,400만 파라미터의 GPT 모델의 경우 위 결과에 12를 곱하면 전체 트랜스포머 블록의 파라미터 수를 구할 수 있습니다."
      ],
      "id": "15463dec-520a-47b4-b3ad-e180394fd076"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597e9251-e0a9-4972-8df6-f280f35939f9"
      },
      "source": [
        "**보너스: 파라미터 계산 방법**\n",
        "\n",
        "- 파라미터 계산 방법이 궁금한 사람을 위해 직접 계산해 보죠(`emb_dim=768`이라 가정합니다):\n",
        "\n",
        "피드 포워드 모듈:\n",
        "\n",
        "- 첫 번째 `Linear` 층: 768 입력 × 4×768 출력 + 4×768 편향 유닛 = 2,362,368\n",
        "- 두 번째 `Linear` 층: 4×768 입력 × 768 출력 + 768 편향 유닛 = 2,360,064\n",
        "- 총:  첫 번째 `Linear` 층 + 두 번째 `Linear` 층 = 2,362,368 + 2,360,064 = 4,722,432\n",
        "\n",
        "어텐션 모듈:\n",
        "\n",
        "- `W_query`: 768 입력 × 768 출력 = 589,824\n",
        "- `W_key`: 768 입력 × 768 출력 = 589,824\n",
        "- `W_value`: 768 입력 × 768 출력 = 589,824\n",
        "- `out_proj`: 768 입력 × 768 출력 + 768 편향 유닛 = 590,592\n",
        "- 총: `W_query` + `W_key` + `W_value` + `out_proj` = 3×589,824 + 590,592 = 2,360,064"
      ],
      "id": "597e9251-e0a9-4972-8df6-f280f35939f9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "2pYSZHa5ZBob"
      },
      "id": "2pYSZHa5ZBob"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 마지막으로 모델에 필요한 메모리 크기를 계산해 보죠:"
      ],
      "metadata": {
        "id": "7J2mcpNPYgAf"
      },
      "id": "7J2mcpNPYgAf"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5131a752-fab8-4d70-a600-e29870b33528",
      "metadata": {
        "id": "5131a752-fab8-4d70-a600-e29870b33528",
        "outputId": "424ad24c-ae6d-45c0-ac1f-36ff57242698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델에 필요한 메모리 공간: 9.00 MB\n"
          ]
        }
      ],
      "source": [
        "# 총 크기를 바이트 단위로 계산합니다(float32라 가정하면 파라미터당 4바이트입니다).\n",
        "total_size_bytes = total_params * 4\n",
        "\n",
        "# 메가바이트로 변환합니다.\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"모델에 필요한 메모리 공간: {total_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f7b7c7f-0fa1-4d30-ab44-e499edd55b6d"
      },
      "source": [
        "### 연습문제 4.2: 더 큰 GPT 모델 초기화하기"
      ],
      "id": "0f7b7c7f-0fa1-4d30-ab44-e499edd55b6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310b2e05-3ec8-47fc-afd9-83bf03d4aad8"
      },
      "source": [
        "- **GPT2-small** (본문에서 구현한 1억 2,400만 모델):\n",
        "    - \"emb_dim\" = 768\n",
        "    - \"n_layers\" = 12\n",
        "    - \"n_heads\" = 12\n",
        "\n",
        "- **GPT2-medium:**\n",
        "    - \"emb_dim\" = 1024\n",
        "    - \"n_layers\" = 24\n",
        "    - \"n_heads\" = 16\n",
        "\n",
        "- **GPT2-large:**\n",
        "    - \"emb_dim\" = 1280\n",
        "    - \"n_layers\" = 36\n",
        "    - \"n_heads\" = 20\n",
        "\n",
        "- **GPT2-XL:**\n",
        "    - \"emb_dim\" = 1600\n",
        "    - \"n_layers\" = 48\n",
        "    - \"n_heads\" = 25"
      ],
      "id": "310b2e05-3ec8-47fc-afd9-83bf03d4aad8"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "90185dea-81ca-4cdc-aef7-4aaf95cba946"
      },
      "outputs": [],
      "source": [
        "def get_config(base_config, model_name=\"gpt2-small\"):\n",
        "    GPT_CONFIG = base_config.copy()\n",
        "\n",
        "    if model_name == \"gpt2-small\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 768\n",
        "        GPT_CONFIG[\"n_layers\"] = 12\n",
        "        GPT_CONFIG[\"n_heads\"] = 12\n",
        "\n",
        "    elif model_name == \"gpt2-medium\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1024\n",
        "        GPT_CONFIG[\"n_layers\"] = 24\n",
        "        GPT_CONFIG[\"n_heads\"] = 16\n",
        "\n",
        "    elif model_name == \"gpt2-large\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1280\n",
        "        GPT_CONFIG[\"n_layers\"] = 36\n",
        "        GPT_CONFIG[\"n_heads\"] = 20\n",
        "\n",
        "    elif model_name == \"gpt2-xl\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1600\n",
        "        GPT_CONFIG[\"n_layers\"] = 48\n",
        "        GPT_CONFIG[\"n_heads\"] = 25\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"잘못된 모델 이름입니다: {model_name}\")\n",
        "\n",
        "    return GPT_CONFIG\n",
        "\n",
        "\n",
        "def calculate_size(model):\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"총 파라미터 개수: {total_params:,}\")\n",
        "\n",
        "    total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "    print(f\"가중치 묶기를 고려한 훈련 가능한 파라미터 개수: {total_params_gpt2:,}\")\n",
        "\n",
        "    # 총 크기를 바이트 단위로 계산합니다(float32라 가정하면 파라미터당 4바이트입니다).\n",
        "    total_size_bytes = total_params * 4\n",
        "\n",
        "    # 메가바이트로 변환합니다.\n",
        "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "    print(f\"모델에 필요한 메모리 공간: {total_size_mb:.2f} MB\")"
      ],
      "id": "90185dea-81ca-4cdc-aef7-4aaf95cba946"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2587e011-78a4-479c-a8fd-961cc40a5fd4",
        "outputId": "e93b9e66-c614-4504-d2e7-ed4ba514057c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "gpt2-small:\n",
            "총 파라미터 개수: 163,009,536\n",
            "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 124,412,160\n",
            "모델에 필요한 메모리 공간: 621.83 MB\n",
            "\n",
            "\n",
            "gpt2-medium:\n",
            "총 파라미터 개수: 406,212,608\n",
            "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 354,749,440\n",
            "모델에 필요한 메모리 공간: 1549.58 MB\n",
            "\n",
            "\n",
            "gpt2-large:\n",
            "총 파라미터 개수: 838,220,800\n",
            "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 773,891,840\n",
            "모델에 필요한 메모리 공간: 3197.56 MB\n",
            "\n",
            "\n",
            "gpt2-xl:\n",
            "총 파라미터 개수: 1,637,792,000\n",
            "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 1,557,380,800\n",
            "모델에 필요한 메모리 공간: 6247.68 MB\n"
          ]
        }
      ],
      "source": [
        "for model_abbrev in (\"small\", \"medium\", \"large\", \"xl\"):\n",
        "    model_name = f\"gpt2-{model_abbrev}\"\n",
        "    CONFIG = get_config(GPT_CONFIG_124M, model_name=model_name)\n",
        "    model = GPTModel(CONFIG)\n",
        "    print(f\"\\n\\n{model_name}:\")\n",
        "    calculate_size(model)"
      ],
      "id": "2587e011-78a4-479c-a8fd-961cc40a5fd4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6cO4jufZGXV"
      },
      "source": [
        "---"
      ],
      "id": "A6cO4jufZGXV"
    },
    {
      "cell_type": "markdown",
      "id": "da5d9bc0-95ab-45d4-9378-417628d86e35",
      "metadata": {
        "id": "da5d9bc0-95ab-45d4-9378-417628d86e35"
      },
      "source": [
        "## 4.7 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172",
      "metadata": {
        "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172"
      },
      "source": [
        "- 앞에서 구현한 GPT와 같은 LLM은 한 번에 하나의 단어를 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caade12a-fe97-480f-939c-87d24044edff",
      "metadata": {
        "id": "caade12a-fe97-480f-939c-87d24044edff"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/16.webp\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13",
      "metadata": {
        "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13"
      },
      "source": [
        "- 다음에 나오는 `generate_text_simple` 함수는 간단하고 빠르게 텍스트를 생성하는 그리디 디코딩(greedy decoding)을 구현합니다.\n",
        "- 그리디 디코딩에서는 각 단계마다 모델이 가장 높은 확률을 가진 단어(또는 토큰)을 다음 출력으로 선택합니다(가장 높은 로짓이 가장 높은 확률에 대응됩니다. 따라서 기술적으로는 명시적으로 소프트매맥스 함수를 적용할 필요가 없습니다).\n",
        "- 다음 장에서 조금 더 고급 기법을 사용한 `generate_text` 함수를 구현하겠습니다.\n",
        "- 다음 그림은 GPT 모델이 주어진 문맥을 기반으로 다음 토큰을 생성하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee0f32c-c18c-445e-b294-a879de2aa187",
      "metadata": {
        "id": "7ee0f32c-c18c-445e-b294-a879de2aa187"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/17.webp\" width=\"800px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6",
      "metadata": {
        "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx는 현재 문맥이 담긴 (batch, n_tokens) 크기의 인덱스 배열입니다\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # 현재 문맥이 모델이 지원하는 문맥 크기를 초과하면 잘라냅니다.\n",
        "        # 예를 들어, LLM이 5개 토큰만 지원하고 문맥 크기가 10이라면,\n",
        "        # 마지막 5개 토큰만 문맥으로 사용합니다.\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # 예측을 만듭니다.\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # 마지막 타임 스텝만 사용하므로\n",
        "        # (batch, n_token, vocab_size)가 (batch, vocab_size)가 됩니다.\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # 확률을 얻기 위해 소프트맥스를 적용합니다.\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # 가장 높은 확률 값을 가진 항목의 인덱스를 얻습니다.\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # 선택한 인덱스를 현재 시퀀스에 추가합니다.\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030",
      "metadata": {
        "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030"
      },
      "source": [
        "- `generate_text_simple`는 한 번에 하나의 토큰을 만드는 반복적인 과정을 구현합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/18.webp\" width=\"700px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce",
      "metadata": {
        "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce"
      },
      "source": [
        "- 입력 샘플을 준비해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
      "metadata": {
        "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
        "outputId": "f1f545d8-e80d-48d4-bc7e-a02429c7c3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩된 ID: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"인코딩된 ID:\", encoded)\n",
        "\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
      "metadata": {
        "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
        "outputId": "f2307f9e-a6dd-49c1-98ae-0d51a8b4941e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "출력: tensor([[15496,    11,   314,   716, 17238, 17994,  6766,  3592,  9399,  7893]])\n",
            "출력 길이: 10\n"
          ]
        }
      ],
      "source": [
        "model.eval() # 드롭아웃 끄기\n",
        "\n",
        "out = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=encoded_tensor,\n",
        "    max_new_tokens=6,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"출력:\", out)\n",
        "print(\"출력 길이:\", len(out[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d131c00-1787-44ba-bec3-7c145497b2c3",
      "metadata": {
        "id": "1d131c00-1787-44ba-bec3-7c145497b2c3"
      },
      "source": [
        "- 배치 차원을 삭제하고 텍스트로 다시 변환합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
      "metadata": {
        "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
        "outputId": "78d57f00-eb90-46d5-cd43-53204e293806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am exploitationasonable sky societyIO asks\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70",
      "metadata": {
        "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70"
      },
      "source": [
        "- 모델이 훈련되지 않았기 때문에 위와 같이 랜덤한 텍스트가 출력됩니다.\n",
        "- 다음 장에서 이 모델을 훈련하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5f2306e-5dc8-498e-92ee-70ae7ec37ac1"
      },
      "source": [
        "### 연습문제 4.3: 별도의 드롭아웃 비율 사용하기"
      ],
      "id": "f5f2306e-5dc8-498e-92ee-70ae7ec37ac1"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5fee2cf5-61c3-4167-81b5-44ea155bbaf2"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M_V2 = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate_emb\": 0.1,        # 임베딩 층 드롭아웃\n",
        "    \"drop_rate_attn\": 0.1,       # 멀티 헤드 어텐션 드롭아웃\n",
        "    \"drop_rate_shortcut\": 0.1,   # 숏컷 연결 드롭아웃\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "id": "5fee2cf5-61c3-4167-81b5-44ea155bbaf2"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5aa1b0c1-d78a-48fc-ad08-4802458b43f7"
      },
      "outputs": [],
      "source": [
        "class TransformerBlockV2(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate_attn\"], # 멀티 헤드 어텐션 드롭아웃\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate_shortcut\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 어텐션 블록을 위한 숏컷 연결\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # 크기 [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # 원래 입력을 더합니다.\n",
        "\n",
        "        # 피드 포워드 블록을 위한 숏컷 연결\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # 원래 입력을 더합니다.\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModelV2(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate_emb\"]) # 임베딩 층 드롭아웃\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlockV2(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # 크기 [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "id": "5aa1b0c1-d78a-48fc-ad08-4802458b43f7"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1d013d32-c275-4f42-be21-9010f1537227"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModelV2(GPT_CONFIG_124M_V2)"
      ],
      "id": "1d013d32-c275-4f42-be21-9010f1537227"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Tt3U6jM5ZeUf"
      },
      "id": "Tt3U6jM5ZeUf"
    },
    {
      "cell_type": "markdown",
      "id": "a35278b6-9e5c-480f-83e5-011a1173648f",
      "metadata": {
        "id": "a35278b6-9e5c-480f-83e5-011a1173648f"
      },
      "source": [
        "## 요약\n",
        "\n",
        "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}