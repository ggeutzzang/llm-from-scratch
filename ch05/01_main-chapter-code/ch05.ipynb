{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e846e9cf",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {
    "id": "45398736-7e89-4263-89c8-92153baff553"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92b989e9-da36-4159-b212-799184764dd9",
    "outputId": "b0b8ff6f-ed16-495b-bce0-3e3d7cac4d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.0\n",
      "numpy 버전: 2.0.2\n",
      "tiktoken 버전: 0.9.0\n",
      "torch 버전: 2.6.0+cu124\n",
      "tensorflow 버전: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\" # OpenAI의 사전 훈련된 가중치를 위해서\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {
    "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
   },
   "source": [
    "- 이 장에서 LLM을 사전 훈련하기 위해 훈련 루프를 구현하고 기본적인 모델 평가 방법을 알아 보겠습니다.\n",
    "- 이 장의 끝에서는 OpenAI의 사전 훈련된 가중치를 우리가 직접 구현한 모델에 로드해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {
    "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {
    "id": "0d214765-7a73-42d5-95e9-302154b29db9"
   },
   "source": [
    "- 이 장에서 다루는 주제는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {
    "id": "f67711d4-8391-4fee-aeef-07ea53dd5841"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 텍스트 생성 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {
    "id": "a3350f8c-5181-4f9b-a789-4523105e98f2"
   },
   "source": [
    "- 이전 장에 코드를 사용하여 GPT 모델을 초기화하는 방법을 간략히 정리합니다.\n",
    "- 그다음 LLM을 위한 기본적인 평가 지표를 소개합니다.\n",
    "- 이 절의 마지막에서 이 평가 지표를 훈련 세트와 검증 세트에 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 GPT를 사용해 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {
    "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
   },
   "source": [
    "- 이전 장의 코드를 사용하여 GPT 모델을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oujnEbGCRVJe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oujnEbGCRVJe",
    "outputId": "0477322f-88af-4e48-af9d-ab6843540cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-06 03:19:11--  https://bit.ly/3HlFmc8\n",
      "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
      "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/previous_chapters.py [following]\n",
      "--2025-06-06 03:19:11--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/previous_chapters.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9905 (9.7K) [text/plain]\n",
      "Saving to: ‘previous_chapters.py’\n",
      "\n",
      "previous_chapters.p 100%[===================>]   9.67K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-06-06 03:19:11 (15.6 MB/s) - ‘previous_chapters.py’ saved [9905/9905]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 깃허브에서 previous_chapters.py 파일을 다운로드합니다.\n",
    "!wget https://bit.ly/3HlFmc8 -O previous_chapters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "id": "86000d74-624a-48f0-86da-f41926cb9e04"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 어휘 사전 크기\n",
    "    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n",
    "    \"emb_dim\": 768,        # 임베딩 차원\n",
    "    \"n_heads\": 12,         # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,        # 층 개수\n",
    "    \"drop_rate\": 0.1,      # 드롭아웃 비율\n",
    "    \"qkv_bias\": False      # 쿼리-키-값 생성시 편향 사용 여부\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 추론 시에는 드롭아웃을 비활성화합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {
    "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
   },
   "source": [
    "- 위에서 드롭아웃을 0.1로 지정했지만 요즘에는 드롭아웃을 사용하지 않고 LLM을 훈련하는 경우가 많습니다.\n",
    "- 최신 LLM은 (초기 GPT 모델과 달리) 쿼리, 키, 값 행렬을 위한 `nn.Linear` 층에서 편향 벡터를 사용하지 않습니다. 그래서 `\"qkv_bias\": False`로 지정합니다.\n",
    "- 모델 훈련에 필요한 계산 자원을 절감하기 위해 문맥 길이(`context_length`)를 256 토큰으로 줄입니다. 원본 1억 2,400만 파라미터의 GPT-2 모델은 1024개의 토큰을 사용했습니다.\n",
    "  - 대부분의 독자들은 이 코드 예제를 랩탑 컴퓨터에서 실행하기 때문입니다.\n",
    "  - 하지만 `context_length`를 1,024개 토큰으로 늘려서 실험해도 괜찮습니다(어떤 코드도 바꿀 필요가 없습니다)\n",
    "  - 나중에 `context_length`가 1,024인 모델을 사전 훈련된 가중치에서 로드하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {
    "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
   },
   "source": [
    "- 그 다음이 이전 장에서 만든 `generate_text_simple` 함수를 사용해 텍스트를 생성합니다.\n",
    "- 또한 두 개 유틸리티 함수 `text_to_token_ids`와 `token_ids_to_text`를 정의합니다. 이 장에서 토큰과 텍스트 표현 사이를 전환하는데 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {
    "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
    "outputId": "8ef14a49-e39f-47a8-82dd-d99cb5129c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 배치 차원을 삭제합니다\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {
    "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
   },
   "source": [
    "- 위해서 볼 수 있듯이 모델이 아직 훈련되지 않았기 때문에 좋은 텍스트를 생성하지 못합니다.\n",
    "- 훈련 과정에서 어떤 것이 좋은 텍스트인지 어떻게 정량적으로 측정할 수 있을까요?\n",
    "- 다음 절에서 훈련 과정을 모니터링할 수 있도록 생성된 출력의 손실을 계산하는 지표를 소개합니다.\n",
    "- LLM 미세 튜닝을 다루는 다음 장에서 모델의 품질을 측정하는 또 다른 방법을 소개하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 텍스트 생성 손실 계산하기: 크로스 엔트로피와 혼잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {
    "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440"
   },
   "source": [
    "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 `inputs` 텐서가 있다고 가정해보죠.\n",
    "- `inputs`에 해당하는 `targets`은 모델이 생성 해야할 토큰 ID를 담고 있습니다.\n",
    "- 2장에서 데이터 로더를 구현할 때 설명했듯이 `targets`은 `inputs`에서 한 토큰씩 앞으로 이동한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {
    "id": "33dc0645-ac2c-4973-9b40-6da40515bede"
   },
   "source": [
    "- `inputs`을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
    "- 각각의 토큰는 어휘 사전 크기에 해당하는 50,257차원의 벡터입니다.\n",
    "- 소프트맥스 함수를 적용하여 로짓 텐서을 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
    "outputId": "0bd73b69-ce28-49da-c50c-4bd71431dfcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # 어휘 사전의 각 토큰에 대한 확률\n",
    "print(probas.shape) # 크기: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {
    "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b"
   },
   "source": [
    "- 매우 작은 어휘 사전을 사용하는 아래 그림에서 확률 점수를 텍스트로 바꾸는 방법을 보여 줍니다. 이 장의 끝에서 이에 대해 논의하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {
    "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {
    "id": "e8480efd-d419-4954-9ecc-2876055334bd"
   },
   "source": [
    "- 이전 장에서 설명했듯이 `argmax` 함수를 적용하여 확률 점수를 토큰 ID 바꿀 수 있습니다.\n",
    "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257 차원의 벡터를 생성합니다. `argmax` 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {
    "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144"
   },
   "source": [
    "- 배치에는 각각 세 개 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3 크기의 예측 토큰을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "922c5add-872d-4b34-bafb-cbbf9e3f2d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 ID:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"토큰 ID:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {
    "id": "cee4072c-21ed-4df7-8721-dd2535362573"
   },
   "source": [
    "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
    "outputId": "c63881b6-ead6-4dfe-96aa-e5eba4b9f65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 타깃:  effort moves you\n",
      "두 번째 샘플의 타깃:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"두 번째 샘플의 타깃: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {
    "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2"
   },
   "source": [
    "- 이는 모델이 아직 훈련되지 않았기 때문입니다.\n",
    "- 모델을 훈련하려면 정답 예측(타깃)에서 얼만큼 떨어져 있는지 알아야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {
    "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {
    "id": "c7251bf5-a079-4782-901d-68c9225d3157"
   },
   "source": [
    "- 타겟 인덱스에 해당하는 토큰 확률은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "49d7e770-5372-442f-b307-04ff349ebb19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {
    "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf"
   },
   "source": [
    "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
    "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "31e18cd9-fd38-4427-b199-30d398106851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확률의 로그를 계산합니다.\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {
    "id": "c4261441-a511-4633-9c4c-67998af31b84"
   },
   "source": [
    "- 그 다음 로그 확률의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "fe16249b-5cae-4f5e-a38a-9f8fca65f03f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰에 대한 평균 확률을 계산합니다.\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {
    "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585"
   },
   "source": [
    "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
    "- 로그 때문에 가장 큰 가능한 값은 0이며, 현재는 0에서 부터 멀리 떨어져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {
    "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514"
   },
   "source": [
    "- 딥러닝 에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7722를 최대화하여 0에 가깝게 만드는 것 대신에 10.7722을 최소화하여 0에 가깝게 만듭니다.\n",
    "- -10.7722의 음수 값, 즉 10.7722을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
    "outputId": "4a3bbf96-a858-41f6-adae-2d400f75aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {
    "id": "84eeb868-abd8-4028-82db-107546bf7c2c"
   },
   "source": [
    "- 파이토치는 이전 단계를 수행하는 `cross_entropy` 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {
    "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {
    "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d"
   },
   "source": [
    "- `cross_entropy` 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "f491b58b-4a70-46df-a91f-eb65c470ed86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로짓 크기: torch.Size([2, 3, 50257])\n",
      "타깃 크기: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 로짓의 크기는 (batch_size, num_tokens, vocab_size)입니다.\n",
    "print(\"로짓 크기:\", logits.shape)\n",
    "\n",
    "# 타깃의 크기는 (batch_size, num_tokens)입니다.\n",
    "print(\"타깃 크기:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {
    "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06"
   },
   "source": [
    "- 파이토치의 `cross_entropy` 함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "17bb089b-8339-4535-88e0-b047758c7b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펼친 로짓: torch.Size([6, 50257])\n",
      "펼친 타깃: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"펼친 로짓:\", logits_flat.shape)\n",
    "print(\"펼친 타깃:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {
    "id": "4921a57f-3a79-473e-a863-6d63b495010f"
   },
   "source": [
    "- 타깃은 토큰 ID이며, 최대화해야 할 로짓 텐서의 인덱스를 나타냅니다.\n",
    "- 파이토치의 `cross_entropy` 함수는 최대화할 토큰 인덱스에 대해 자동으로 소프트맥스와 로그 확률 계산을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "521cc506-25aa-476d-d8e4-8deeb1f49d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {
    "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80"
   },
   "source": [
    "- 크로스 엔트로피 손실에 관련된 개념은 LLM의 혼잡도입니다.\n",
    "- 혼잡도는 크로스 엔트로피 손실에 지수 함수를 적용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "2be94cd7-0eb2-44cb-b66f-b5047e58e5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {
    "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7"
   },
   "source": [
    "- 혼잡도는 모델이 각 단계에서 불확실해하는 실제 어휘사전 크기를 나타내기 때문에 원시 손실 값보다 이해하기 더 쉽습니다(이 예에서는 48,725개 단어 또는 토큰).\n",
    "- 다른 말로 하면, 혼잡도는 모델이 예측한 확률 분포가 데이터셋에 있는 단어의 실제 분포와 얼마나 잘 맞는지를 측정합니다.\n",
    "- 손실과 비슷하게 낮은 혼잡도는 모델 예측이 실제 분포에 가깝다는 것을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {
    "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
   },
   "source": [
    "- LLM 훈련을 위해 비교적 작은 데이터셋을 사용합니다(사실 단편 소설 하나를 사용합니다).\n",
    "- 이유는 다음과 같습니다.\n",
    "  - 적절한 GPU가 없는 랩탑 컴퓨터에서 몇 분 안에 코드 예제가 실행되어야 합니다.\n",
    "  - 교육 목적을 위해 훈련이 비교적 빨리 끝나야 합니다(몇 주가 아니라 몇 분 만에).\n",
    "  - 사용 권리를 위반하지 않으며 깃허브 저장소에 저장할 수 있는 크기의 공개된 텍스트를 사용해야 합니다.\n",
    "- 예를 들어, Llama 2 7B는 2조 개의 토큰에서 훈련하기 위해 A100 GPU에서 184,320 GPU 시간이 필요합니다.\n",
    "  - 이 글을 쓰는 시점에, AWS의 8xA100 클라우드 서버의 시간당 가격은 약 \\$30입니다.\n",
    "  - 따라서 대략 계산하면 이 LLM을 훈련하는데 184,320 / 8 * \\$30 =  \\$690,000이 듭니다.\n",
    "- 아래에서는 2장에서 다루었던 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {
    "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {
    "id": "379330f1-80f4-4e34-8724-41d892b04cee"
   },
   "source": [
    "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100 개의 문자를 출력하여 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "66ae3ffd-3aa1-4127-8217-cc96e2334681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 처음 99개 문자\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2XPde_ThM_e",
    "outputId": "1a4b493c-daf3-41dd-93d5-f6d9fbba5d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# 마지막 99개 문자\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c121b247-7398-4379-bb6d-c7b4ee79dfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자: 20479\n",
      "토큰: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"문자:\", total_characters)\n",
    "print(\"토큰:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {
    "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
   },
   "source": [
    "이 텍스트의 토큰이 5,145개 뿐이라 LLM을 훈련하기에 너무 적어 보일 수 있습니다. 하지만 이는 교육적인 목적을 위해서입니다(나중에 사전 훈련된 가중치를 로드하겠습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {
    "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
   },
   "source": [
    "- 그 다음 데이터셋을 훈련 세트와 검증 세트로 나누고 2장의 데이터 로더를 사용해 LLM 훈련을 위한 배치를 준비합니다.\n",
    "- 시각화때문에 아래 그림은 `max_length=6`라고 가정하지만, 훈련 데이터 로더에서 `max_length`는 LLM이 지원하는 문맥 길이와 같습니다.\n",
    "- 아래 그림은 간단하게 나타내려고 입력 토큰만 보여줍니다.\n",
    "  - LLM을 텍스트에 있는 다음 단어를 예측하도록 훈련하기 때문에 타깃은 한 토큰씩 이동한 것외에는 입력과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {
    "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {
    "id": "0959c855-f860-4358-8b98-bc654f047578"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 훈련 세트 비율\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {
    "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
   },
   "outputs": [],
   "source": [
    "# 유효성 검사\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {
    "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
   },
   "source": [
    "- 컴퓨팅 자원을 절감하고 데이터셋이 매우 작기 때문에 비교적 작은 배치 크기를 사용합니다.\n",
    "- 예를 들어 Llama 2 7B는 배치 크기 1024에서 훈련되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {
    "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
   },
   "source": [
    "- 데이터가 올바르게 로드되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
    "outputId": "d4938885-9384-4f7f-80d2-505c8b929e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "검증 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 로더:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\n검증 데이터 로더:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {
    "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
   },
   "source": [
    "- 토큰 크기가 예상 범위 안에 있는지 추가로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "07d7c153-bc35-4d46-c42d-bc4af1465699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 토큰 수: 4608\n",
      "검증 토큰 수: 512\n",
      "모든 토큰 수: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"훈련 토큰 수:\", train_tokens)\n",
    "print(\"검증 토큰 수:\", val_tokens)\n",
    "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {
    "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
   },
   "source": [
    "- 주어진 배치에서 크로스 엔트로피 손실을 계산 하는 유틸리티 함수를 작성 합니다\n",
    "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # num_batches가 데이터 로더에 있는 배치 개수보다 크면\n",
    "        # 배치 횟수를 데이터 로더에 있는 총 배치 개수로 맞춥니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {
    "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
   },
   "source": [
    "- CUDA를 지원하는 GPU를 가지고 있다면 어떤 코드도 변경할 필요 없이 GPU 에서 LLM을 훈련할 수 있습니다.\n",
    "- `device` 설정을 통해 데이터를 LLM 모델과 동일한 장치에 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
    "outputId": "0079b513-9f13-400c-f805-4b1a0b6dc035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실: 10.987583372328016\n",
      "검증 손실: 10.981104850769043\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 노트:\n",
    "# 애플 실리콘 칩에서 코드를 실행하는 경우 다음 주석을 해제하세요.\n",
    "# (M3 맥북 에어에서 측정하면) 애플 CPU보다 약 2배 빠릅니다. 하지만 손실 값은 조금 다를 수 있습니다.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # nn.Module classes의 경우 model = model.to(device)로 할당할 필요가 없습니다.\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # 데이터 로더에서 셔플링이 일어나므로 재현가능성을 위해 설정합니다.\n",
    "\n",
    "with torch.no_grad(): # 모델을 아직 훈련하지 않으므로 효율성을 위해 그레이디언트 추적을 끕니다.\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"훈련 손실:\", train_loss)\n",
    "print(\"검증 손실:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {
    "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 LLM 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {
    "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
   },
   "source": [
    "- 이 절에서는 LLM 훈련을 위한 코드를 구현합니다.\n",
    "- 여기서는 간단한 훈련 함수를 만듭니다(이 훈련 함수를 학습률 워밍업, 코사인 어닐링, 그레이디언트 클리핑 같은 고급 기법으로 확장하고 싶다면 [부록 D](../../appendix-D/01_main-chapter-code)를 참고하세요).\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 손실과 지금까지 처리한 토큰 수를 추적하기 위해 리스트를 초기화합니다.\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 메인 훈련 루프를 시작합니다.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 훈련 모드로 설정합니다.\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 이전 배치 반복에서 얻은 손실의 그레이디언트를 초기화합니다.\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 손실의 그레이디언트를 계산합니다.\n",
    "            optimizer.step() # 손실의 그레이디언트를 사용하여 모델 가중치를 업데이트합니다.\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 추가적인 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "\n",
    "        # 각 에포크 후에 샘플 텍스트를 출력합니다.\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 간결한 출력 포맷을 위해\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {
    "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
   },
   "source": [
    "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "cf7bc431-5301-498f-bd55-47a429bb5b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 9.818, 검증 손실 9.928\n",
      "에포크 1 (Step 000005): 훈련 손실 8.065, 검증 손실 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "에포크 2 (Step 000010): 훈련 손실 6.622, 검증 손실 7.051\n",
      "에포크 2 (Step 000015): 훈련 손실 6.047, 검증 손실 6.600\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "에포크 3 (Step 000020): 훈련 손실 5.586, 검증 손실 6.477\n",
      "에포크 3 (Step 000025): 훈련 손실 5.523, 검증 손실 6.399\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "에포크 4 (Step 000030): 훈련 손실 5.128, 검증 손실 6.366\n",
      "에포크 4 (Step 000035): 훈련 손실 4.941, 검증 손실 6.366\n",
      "Every effort moves you a a to the a. Gisburn, and a. Gisburn. I had the of the of the of the of the of the of the of the of the of the of the of the of the of the. I had a\n",
      "에포크 5 (Step 000040): 훈련 손실 4.340, 검증 손실 6.246\n",
      "Every effort moves you, with a, in the of the picture--as of the of the of the of the picture of his of the  \"I had been. \"Oh, in the donkey--and it was a little the man of the picture of\n",
      "에포크 6 (Step 000045): 훈련 손실 3.967, 검증 손실 6.181\n",
      "에포크 6 (Step 000050): 훈련 손실 3.451, 검증 손실 6.155\n",
      "Every effort moves you know the \"Oh, and.  \"Oh, and in a little: \"There, and in the    \"Oh, and I had been the donkey.            \n",
      "에포크 7 (Step 000055): 훈련 손실 3.466, 검증 손실 6.195\n",
      "에포크 7 (Step 000060): 훈련 손실 2.666, 검증 손실 6.134\n",
      "Every effort moves you know the picture.  \"I looked he was a little the last word.           \"I he was his pictures-c.             \n",
      "에포크 8 (Step 000065): 훈련 손실 2.208, 검증 손실 6.141\n",
      "에포크 8 (Step 000070): 훈련 손실 1.879, 검증 손실 6.228\n",
      "Every effort moves you know,\" was not that the picture.  \"I had the last word. Gisburn's an!  \"Oh, in the moment--as Jack himself, as he was his own the donkey. \"There were days when I\n",
      "에포크 9 (Step 000075): 훈련 손실 1.499, 검증 손실 6.230\n",
      "에포크 9 (Step 000080): 훈련 손실 1.174, 검증 손실 6.250\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, with a Mrs. Gisburn's open countenance. \"It's his pictures with a \"strongest,\" she was\n",
      "에포크 10 (Step 000085): 훈련 손실 0.901, 검증 손실 6.328\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"         He placed them at my elbow and as I turned, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "# 노트:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {
    "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204"
   },
   "source": [
    "- 여러분의 결과와 손실 값이 조금 다를 수 있습니다. 대체적으로 비슷하다면 (훈련 손실은 1이하이고 검증 손실은 7이하이면) 걱정할 필요가 없습니다.\n",
    "- GPU 하드웨어와 CUDA 버전 또는 파이토치의 신버전에서 바뀐 변화 때문에 차이가 발생할 수 있습니다.\n",
    "- CPU에서 이 예제를 실행하더라도 작은 차이를 볼 수 있습니다. 이런 차이를 만드는 원인 중 하나는 파이토치가 컴파일된 운영체제에 따라 `nn.Dropout`의 동작 방식이 다르기 때문입니다. 자세한 내용은 파이토치 [깃허브 이슈](https://github.com/pytorch/pytorch/issues/121595)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "8ae968b9-21de-42b5-fe1b-b91520e93541"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # 처리한 토큰 수에 대한 두 번째 x 축을 만듭니다.\n",
    "    ax2 = ax1.twiny()  # y 축을 공유하는 두 번째 x 축을 만듭니다.\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다.\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {
    "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
   },
   "source": [
    "- 위 결과를 보면 모델이 처음에는 이해할 수 없는 단어를 생성하지만 마지막으로 갈수록 문법적으로 어느 정도 정확한 문장을 생성합니다.\n",
    "- 하지만 훈련 세트 손실과 검증 세트 손실을 보면 모델이 과대적합되기 시작합니다.\n",
    "- 마지막 부분의 몇 문장을 확인하면 훈련 세트에 있는 내용이라는 것을 알 수 있습니다. 모델이 단순히 훈련 데이터를 암기한 것입니다.\n",
    "- 매우 작은 훈련 세트를 사용하고 모델을 여러 에포크에서 훈련하고 있기 때문에 과대적합이 일어납니다.\n",
    "  - 여기서는 교육적인 목적을 위해 LLM을 훈련합니다. 모델이 일관된 텍스트를 생성하는 방법을 학습할 수 있는지 확인하는 것이 주요 목적입니다.\n",
    "  - 대량의 고가 하드웨어에서 몇 주 또는 몇 달 동안 이런 모델을 훈련하는 대신에 나중에 사전 훈련된 가중치를 로드하여 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {
    "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {
    "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
   },
   "source": [
    "- 더 큰 훈련 데이터셋에서 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 무작위성을 제어하기 위한 디코딩 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {
    "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
   },
   "source": [
    "- 위에서 구현한 GPT 모델처럼 작은 LLM의 추론 비용은 비교적 저렴합니다. 따라서 훈련에 GPU를 사용했더라도 추론에서는 GPU를 사용할 필요가 없습니다.\n",
    "- 이전 장에서 만든 `generate_text_simple` 함수를 사용해 한 번에 하나의 단어(또는 토큰)씩 새로운 텍스트를 생성할 수 있습니다.\n",
    "- 5.1.2절에서 설명했듯이 생성된 다음 토큰은 어휘사전의 모든 토큰 중에서 확률 점수가 가장 높은 토큰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
    "outputId": "f058807a-fc7a-412e-afaf-635f6cb4a65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {
    "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
   },
   "source": [
    "- `generate_text_simple` 함수를 여러번 실행하더라도 LLM은 항상 동일한 출력을 생성합니다.\n",
    "- `generate_text_simple`를 수정하기 위해 두 가지 디코딩 전략을 소개합니다. *온도 스케일링*과 *탑-k* 샘플링입니다.\n",
    "- 이를 사용해 모델이 생성된 텍스트의 무작위성과 다양성을 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {
    "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
   },
   "source": [
    "### 5.3.1 온도 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {
    "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
   },
   "source": [
    "- 이전에는 `torch.argmax`를 사용해 항상 가장 높은 확률을 가진 토큰을 다음 토큰으로 샘플링했습니다.\n",
    "- 다양성을 추가하기 위해 확률 분포에서 샘플링하도록 `torch.multinomial(probs, num_samples=1)`을 사용해 토큰을 샘플링할 수 있습니다.\n",
    "- 여기서 각 인덱스 선택 가능성은 입력 텐서에 있는 확률에 따라 결정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {
    "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
   },
   "source": [
    "- 여기에서 다음 토큰 생성에 대해 간략히 정리해 보겠습니다. 설명을 위해 매우 작은 어휘사전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
    "outputId": "828ff3ce-c71f-46b0-ea3b-671dd50f9b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 입력이 \"every effort moves you\"이고\n",
    "# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다고 가정해 보죠.\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 생성될 토큰은 다음과 같습니다.\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
    "outputId": "716ff69f-69ee-4e59-a794-d6c940541b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {
    "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
   },
   "source": [
    "- `torch.argmax`로 가장 가능성이 높은 토큰을 결정하는 대신에 `torch.multinomial(probas, num_samples=1)`를 사용해 소프트맥스 분포에서 샘플링하여 가장 가능성이 높은 토큰을 결정할 수 있습니다.\n",
    "- 설명을 위해 원래 소프트맥스 분포에서 1,000번 토큰을 샘플링해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
    "outputId": "fc9f744f-fe1d-4cb8-c604-717a9778d0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # 재현가능성을 위한 랜덤 시드\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {
    "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
   },
   "source": [
    "- 온도 스케일링으로 분포와 선택 과정을 조절할 수 있습니다.\n",
    "- \"온도 스케일링\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미합니다.\n",
    "- 1보다 큰 온도는 소프트맥스 함수를 적용한 후에 더 균등한 토큰 확률 분포를 만듭니다.\n",
    "- 1보다 작은 온도는 소프트맥스 함수를 적용한 후에 더 결정론적인 분포(더 날카롭거나 뾰족한 분포)를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {
    "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 온도 값\n",
    "temperatures = [1, 0.1, 5]  # 원본, 낮은 온도, 높은 온도\n",
    "\n",
    "# 스케일을 조정한 확률 계산\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
    "outputId": "c8723184-2912-428d-ee95-72b6c3400565"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {
    "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
   },
   "source": [
    "- 온도 0.1로 스케일을 조정하면 더 뾰족한 분포를 만들어, `torch.argmax`에 가까워져 항상 가장 가능성있는 토큰이 선택됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
    "outputId": "96fb49ed-4e7e-42e7-c293-9ebb64d30c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {
    "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
   },
   "source": [
    "- 온도 5로 스케일을 조정한 확률은 더 균등한 분포가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
    "outputId": "f259084b-e182-4b0c-9884-1f2bbdb8669f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {
    "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
   },
   "source": [
    "- LLM 입력이 \"every effort moves you\"일 경우 위와 같은 방법을 사용하면 \"every effort moves you pizza\"와 같이 3.2%의 확률(1,000번 중에 32번)로 이따금 말이 안되는 텍스트를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {
    "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
   },
   "source": [
    "### 5.3.2 탑-k 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {
    "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
   },
   "source": [
    "- 높은 온도를 사용하여 출력의 다양성을 증가시키면서 말이 안되는 문장이 생성될 가능성을 낮추기 위해 가장 가능성있는 상위 k개 토큰으로 샘플링될 토큰을 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {
    "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=700px>\n",
    "\n",
    "- (이 그림의 숫자는 간단하게 나타내려고 소숫점 두자리 이후를 자른 값입니다. 소프트맥스 열의 값은 모두 더해서 1.0이 되어야 합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {
    "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
   },
   "source": [
    "- 코드로는 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
    "outputId": "ece3064e-99ce-4731-a6fd-97ac933b397a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탑-k 로짓: tensor([6.7500, 6.2800, 4.5100])\n",
      "탑-k 위치: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"탑-k 로짓:\", top_logits)\n",
    "print(\"탑-k 위치:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
    "outputId": "1c678fa8-8b3a-4e65-bf54-8f985c5977c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {
    "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00"
   },
   "source": [
    "> 노트:  \n",
    ">\n",
    ">  이전 코드를 조금 더 효율적으로 구현하는 방법은 다음과 같습니다.\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # -inf 값을 담은 텐서를 만듭니다.\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # -inf 텐서에 상위 k개 값을 복사합니다.\n",
    "> ```\n",
    "> <br>\n",
    "> 자세한 내용은 다음을 참고하세요: https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
    "outputId": "bdc59492-677b-4995-e025-5bdaf36d55e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {
    "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
   },
   "source": [
    "### 5.3.3 텍스트 생성 함수 수정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {
    "id": "34770423-473d-46f6-a5fa-6b2979564d26"
   },
   "source": [
    "- 이전 두 개의 절에서 온도 스케일링과 탑-k 샘플링을 소개했습니다.\n",
    "- 두 개념을 사용해 앞서 LLM으로 텍스트를 생성할 때 사용한 `generate_sample` 함수를 수정해 새로운 `generate` 함수를 만들어 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {
    "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # for 루프는 이전과 동일합니다. 로짓을 받아 마지막 타임 스텝만 사용합니다.\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 탑-k 샘플링으로 로짓을 필터링합니다.\n",
    "        if top_k is not None:\n",
    "            # 탑-k 값만 유지합니다.\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 온도 스케일링을 적용합니다.\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 소프트맥스 함수를 적용하여 확률을 얻습니다.\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 분포에서 샘플링합니다.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 온도 스케일링을 사용하지 않는 경우 이전처럼 그리디 샘플링을 사용해 다음 토큰을 선택합니다.\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # eos_id가 지정되어 있고 EoS 토큰을 만나면 생성을 중단합니다.\n",
    "            break\n",
    "\n",
    "        # 이전과 동일하게 샘플링된 인덱스를 현재 시퀀스 뒤에 추가합니다.\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
    "outputId": "4ee72e26-8e80-414a-97c1-2e4a976f6fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you know began to happen a little wild--I was such a sketch of enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {
    "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
   },
   "source": [
    "## 5.4 파이토치로 모델 로드하고 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {
    "id": "0fc52676-f026-4566-a226-2a90269f9d53"
   },
   "source": [
    "- LLM 훈련에는 계산 비용이 많이 듭니다. 따라서 LLM 가중치를 저장하고 로드하는 것이 중요합니다.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {
    "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
   },
   "source": [
    "- 파이토치에서는 `torch.save` 함수를 `.state_dict()` 메서드 결과에 적용해 소위 `state_dict`인 모델 가중치를 저장하는 것이 권장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {
    "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {
    "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
   },
   "source": [
    "- 그다음 모델 가중치를 새로운 `GPTModel` 클래스 인스턴스에 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {
    "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {
    "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
   },
   "source": [
    "- 일반적인 SGD 대신 Adam이나 AdamW와 같이 적응형 옵티마이저로 LLM을 훈련하는 것이 일반적입니다.\n",
    "- 이런 적응형 옵티마이저는 모델 가중치마다 추가적인 파라미터를 저장합니다. 나중에 사전 훈련을 계속하려면 이 파라미터도 저장하는 것이 맞습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {
    "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {
    "id": "8a0c7295-c822-43bf-9286-c45abc542868"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {
    "id": "4194350e-0409-4a63-8ffd-d3a896509032"
   },
   "source": [
    "## 5.5 오픈AI에서 사전 훈련된 가중치 로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {
    "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
   },
   "source": [
    "- 앞서 하나의 단편 소설로 구성된 작은 데이터셋을 사용해 소규모 GPT-2 모델을 훈련했습니다.\n",
    "- 구텐베르크 프로젝트에 있는 전체 책으로 더 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요.\n",
    "- 다행히 오픈AI는 GPT-2 모델의 가중치를 공개적으로 제공하기 때문에 대규모 말뭉치에서 모델을 재훈련하기 위해 수만에서 수십만 달러를 쓸 필요가 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {
    "id": "127ddbdb-3878-4669-9a39-d231fbdfb834"
   },
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "⚠️ **노트: 일부 사용자는 특히 윈도 운영체제에서 텐서플로의 호환성 때문에 문제가 발생할 수 있습니다. 원본 OpenAI GPT-2 가중치 파일을 로드하기 위해 텐서플로가 필요하며 그다음 파이토치로 변환합니다.\n",
    "텐서플로 관련 이슈가 발생한다면 이 절의 남은 코드를 실행하는 대신 아래 코드를 사용할 수 있습니다.\n",
    "아래 코드는 이전 절에 설명된 변환 과정을 사용해 미리 파이토치용으로 바꾼 가중치를 사용합니다. 자세한 내용은 다음 노트북을 참고하세요. [../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb).**\n",
    "\n",
    "```python\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"다운로드 파일: {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device);\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {
    "id": "75cab892-a165-4f43-9601-f517bc212ab6"
   },
   "source": [
    "- 먼저 OpenAI에서 파일을 다운로드하고 파이썬으로 가중치를 로드하는 코드가 필요합니다.\n",
    "- OpenAI가 [텐서플로](https://www.tensorflow.org/)를 사용했기 때문에 가중치를 로드하기 위해 텐서플로를 설치하고 사용해야 합니다. [tqdm](https://github.com/tqdm/tqdm)은 진행 표시줄을 나타내기 위한 라이브러리입니다.\n",
    "- 필요한 라이브러리를 설치하려면 다음 코드의 주석을 제거하고 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {
    "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8"
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
    "outputId": "a12e595b-367f-4f74-9d3e-d54b233f999e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서플로 버전: 2.18.0\n",
      "tqdm 버전: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"텐서플로 버전:\", version(\"tensorflow\"))\n",
    "print(\"tqdm 버전:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dvJjVQPWpg6B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvJjVQPWpg6B",
    "outputId": "f511afbf-97a9-4565-cb00-0b02b5966672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-06 03:23:56--  https://bit.ly/4kSEn1v\n",
      "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
      "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py [following]\n",
      "--2025-06-06 03:23:56--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6333 (6.2K) [text/plain]\n",
      "Saving to: ‘gpt_download.py’\n",
      "\n",
      "\r",
      "gpt_download.py       0%[                    ]       0  --.-KB/s               \r",
      "gpt_download.py     100%[===================>]   6.18K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-06-06 03:23:57 (60.9 MB/s) - ‘gpt_download.py’ saved [6333/6333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 깃허브에서 gpt_download.py 파일을 다운로드합니다.\n",
    "!wget https://bit.ly/4kSEn1v -O gpt_download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {
    "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed"
   },
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {
    "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc"
   },
   "source": [
    "---\n",
    "\n",
    "**노트**\n",
    "\n",
    "- 드물게 텐서플로 설치 이슈 때문에 위 코드 셀에서 `zsh: illegal hardware instruction python` 오류가 발생할 수 있습니다.\n",
    "- 이 문제를 해결하기 위해 `conda`를 사용해 텐서플로를 설치하는 방법은 [깃허브 이슈](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888)를 참고하세요.\n",
    "- conda 사용에 관한 추가적인 내용은 [Python setup tutorial](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda)을 참고하세요.\n",
    "\n",
    "---\n",
    "\n",
    "- 다음처럼 1억 2,400만 파라미터를 가진 모델의 가중치를 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
    "outputId": "1d3104f3-d7de-4d1d-e94b-0657e48e0b31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 133kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.91MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 174kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:20<00:00, 24.3MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 10.2MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.88MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.89MiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
    "outputId": "b17dbd5e-dd4a-43d6-bed5-ede107d7cea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"설정:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
    "outputId": "a2418b33-893c-41a0-95ee-2c15d5c700bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파라미터 딕셔너리 키: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"파라미터 딕셔너리 키:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
    "outputId": "9e2bebfe-4490-4d4e-8370-548ad5258f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "토큰 임베딩 가중치 텐서의 차원: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"토큰 임베딩 가중치 텐서의 차원:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {
    "id": "466e100c-294e-4afc-a70a-2f398ac4c104"
   },
   "source": [
    "- `model_size` 매개변수에 \"355M\", \"774M\", \"1558M\"도 지정할 수 있습니다.\n",
    "- 이런 모델의 차이점은 다음 그림에 요약되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {
    "id": "20f19d32-5aae-4176-9f86-f391672c8f0d"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {
    "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41"
   },
   "source": [
    "- 위에서 1억 2,400만 파라미터의 GPT-2 모델 가중치를 파이썬으로 로드했습니다. 이제 `GPTModel` 클래스의 인스턴스로 복사해야 합니다.\n",
    "- 먼저, 새로운 `GPTModel` 인스턴스를 초기화합니다.\n",
    "- 원본 GPT 모델은 멀티 헤드 어텐션 모듈의 쿼리, 키, 값 행렬을 위한 선형 층에서 편향 벡터를 사용합니다. 이것이 필수적이지는 않지만 사전 훈련된 가중치를 제대로 로드하기 위해서 `qkv_bias`를 `True`로 설정해야 합니다.\n",
    "- 또한 원본 GPT-2 모델에서 사용한 문맥 크기인 `1024` 토큰을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {
    "id": "9fef90dd-0654-4667-844f-08e28339ef7d"
   },
   "outputs": [],
   "source": [
    "# 딕셔너리로 모델 설정을 저장합니다.\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# 기본 설정을 특정 값으로 업데이트합니다.\n",
    "model_name = \"gpt2-small (124M)\"  # 모델 이름\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {
    "id": "272f29ac-8342-4b3d-a57d-9b0166ced314"
   },
   "source": [
    "- 다음 작업은 OpenAI 가중치를 `GPTModel` 인스턴스에 있는 가중치 텐서에 할당하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {
    "id": "f9a92229-c002-49a6-8cfb-248297ad8296"
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"크기가 다릅니다. left: {left.shape}, right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {
    "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {
    "id": "4f7472cb-54dc-4311-96d8-b2694f885cee"
   },
   "source": [
    "- 모델이 올바르게 로드되었다면 `generate` 함수를 사용해 새로운 텍스트를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
    "outputId": "61844625-73ed-4f32-b20a-7f16924738db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {
    "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
   },
   "source": [
    "- 모델이 일관성 있는 텍스트를 생성했기 때문에 가중치가 올바르게 로드되었다고 확신할 수 있습니다. 이 과정에서 조금만 잘못되어도 모델이 제대로 텍스트를 생성하지 못합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {
    "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
   },
   "source": [
    "- 허깅 페이스 허브에서 가중치를 로드하는 방법은 [../02_alternative_weight_loading](../02_alternative_weight_loading)에 있는 노트북을 참고하세요.\n",
    "- GPT 구조와 (메타에서 개발한) Llama 구조를 비교해 보려면 보너스 콘텐츠 [../07_gpt_to_llama](../07_gpt_to_llama)를 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {
    "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
   },
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {
    "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
   },
   "source": [
    "- [./gpt_train.py](./gpt_train.py)는 훈련 스크립트 파일입니다.\n",
    "- [./gpt_generate.py](./gpt_generate.py)는 OpenAI에서 사전 훈련된 가중치를 로드하여 프롬프트를 기반으로 텍스트를 생성합니다.\n",
    "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
