{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de96a16",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "<a href=\"http://mng.bz/orYv\">밑바닥부터 시작하는 대규모 언어 모델 구축</a> 책 (<a href=\"https://sebastianraschka.com\">Sebastian Raschka</a> 저)을 위한 보충 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e5a91",
   "metadata": {},
   "source": [
    "# 챕터 6 연습 문제 해답\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e9e0f",
   "metadata": {},
   "source": [
    "## 연습 6.1: 컨텍스트 길이 늘리기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e5a2e",
   "metadata": {},
   "source": [
    "모델이 지원하는 최대 토큰 수로 입력을 패딩하려면 최대 길이를 1024로 설정합니다.\n",
    "\n",
    "```python\n",
    "max_length = 1024\n",
    "\n",
    "train_dataset = SpamDataset(base_path / \"train.csv\", max_length=max_length, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(base_path / \"validation.csv\", max_length=max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(base_path / \"test.csv\", max_length=max_length, tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "또는 동일하게 다음을 통해 `max_length`를 정의할 수 있습니다.\n",
    "\n",
    "```python\n",
    "max_length = model.pos_emb.weight.shape[0]\n",
    "```\n",
    "\n",
    "또는\n",
    "\n",
    "```python\n",
    "max_length = BASE_CONFIG[\"context_length\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857b8f7",
   "metadata": {},
   "source": [
    "편의를 위해, 다음과 같이 실행하여 이 실험을 진행할 수 있습니다.\n",
    "\n",
    "```bash\n",
    "python additional-experiments.py --context_length \"model_context_length\"\n",
    "```\n",
    "\n",
    "[../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하면, 이는 훨씬 낮은 테스트 정확도인 78.33% (주요 챕터의 95.67% 대비)를 초래합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39592a3",
   "metadata": {},
   "source": [
    "## 연습 6.2: 전체 모델 미세 조정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118dc47",
   "metadata": {},
   "source": [
    "마지막 트랜스포머 블록만 미세 조정하는 대신, 코드에서 다음 줄을 제거하여 전체 모델을 미세 조정할 수 있습니다.\n",
    "\n",
    "```python\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "```\n",
    "\n",
    "편의를 위해 다음과 같이 실행하여 이 실험을 진행할 수 있습니다.\n",
    "\n",
    "```bash\n",
    "python additional-experiments.py --trainable_layers all\n",
    "```\n",
    "\n",
    "[../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하면 테스트 정확도가 95.67%(메인 챕터)에서 96.67%로 1% 향상됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7fafb",
   "metadata": {},
   "source": [
    "## 연습 6.3: 첫 번째 토큰 대 마지막 토큰 미세 조정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf8b94",
   "metadata": {},
   "source": [
    "마지막 출력 토큰을 미세 조정하는 대신, 다음 코드를\n",
    "\n",
    "```python\n",
    "model(input_batch)[:, -1, :]\n",
    "```\n",
    "\n",
    "에서\n",
    "\n",
    "```python\n",
    "model(input_batch)[:, 0, :]\n",
    "```\n",
    "\n",
    "으로 변경하여 첫 번째 출력 토큰을 미세 조정할 수 있습니다.\n",
    "\n",
    "편의를 위해, [../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하여 다음과 같이 실행하면 이 실험을 할 수 있습니다.\n",
    "\n",
    "```\n",
    "python additional-experiments.py --trainable_token first\n",
    "```\n",
    "\n",
    "이렇게 하면 테스트 정확도가 75.00%로 크게 떨어집니다 (메인 챕터에서는 95.67%).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}